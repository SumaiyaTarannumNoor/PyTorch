{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UOMpNQtBZYf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wy4h6aGqyaso"
      },
      "outputs": [],
      "source": [
        "with open('Naruto.txt', 'r', encoding='utf-8') as f:\n",
        "    txt_content = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7PrdnPnyg6Q"
      },
      "outputs": [],
      "source": [
        "! pip install PyPDF2\n",
        "! pip install python-docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BulNlUMNywXZ"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "\n",
        "pdf_content = \"\"\n",
        "with open('Sakura.pdf', 'rb') as f:\n",
        "    reader = PyPDF2.PdfReader(f)\n",
        "    for page in reader.pages:\n",
        "        pdf_content += page.extract_text() or \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CMUW2u2yqCY"
      },
      "outputs": [],
      "source": [
        "import docx\n",
        "\n",
        "def read_docx(filename):\n",
        "    doc = docx.Document(filename)\n",
        "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "\n",
        "docx_content = read_docx('Sasuke.docx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4p5XvpXy0fP"
      },
      "outputs": [],
      "source": [
        "text = txt_content + pdf_content + docx_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7M6NDzxSF8TT"
      },
      "outputs": [],
      "source": [
        "chars = sorted(list(set(text)))\n",
        "char_to_index = {char: i for i, char in enumerate(chars)}\n",
        "index_to_char = {i: char for i, char in enumerate(chars)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDbPLtA_Gkk9"
      },
      "outputs": [],
      "source": [
        "seq_length = 3\n",
        "sequences = []\n",
        "labels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tM-EqeEiGwCK"
      },
      "outputs": [],
      "source": [
        "for i in range(len(text)-seq_length):\n",
        "  seq = text[i:i + seq_length]\n",
        "  label = text[i + seq_length]\n",
        "  sequences.append([char_to_index[char] for char in seq])\n",
        "  labels.append(char_to_index[label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exT8wtRMHK-p"
      },
      "outputs": [],
      "source": [
        "x = np.array(sequences)\n",
        "y = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip-dJ1uJHTmR"
      },
      "outputs": [],
      "source": [
        "x_tensor = torch.from_numpy(x)\n",
        "y_tensor = torch.from_numpy(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BZ2RMDaHdTN"
      },
      "outputs": [],
      "source": [
        "x_one_hot = torch.nn.functional.one_hot(x_tensor, num_classes = len(chars)).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tADRyEGFH4O8"
      },
      "outputs": [],
      "source": [
        "dataset = TensorDataset(x_one_hot, y_tensor)\n",
        "batch_size = 32\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lp2ZQEBhIP5T"
      },
      "outputs": [],
      "source": [
        "class CharLSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "     super(CharLSTM, self).__init__()\n",
        "     self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "     self.fc = nn.Linear(hidden_size, num_classes)\n",
        "  def forward(self, x):\n",
        "     out, _ = self.lstm(x)\n",
        "     out = out[:, -1, :]\n",
        "     out = self.fc(out)\n",
        "     return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZlp1DI5JT0h"
      },
      "outputs": [],
      "source": [
        "input_size = len(chars)\n",
        "hidden_size = 160\n",
        "num_layers = 6\n",
        "num_classes = len(chars)\n",
        "num_epochs = 300\n",
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9VWMH2vKlzE"
      },
      "outputs": [],
      "source": [
        "model = CharLSTM(input_size, hidden_size, num_layers, num_classes)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7UBJVx4K7u5"
      },
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs):\n",
        "  total_loss = 0\n",
        "  for batch_x, batch_y in dataloader:\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(batch_x)\n",
        "    loss = criterion(outputs, batch_y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  avg_loss = total_loss/len(dataloader)\n",
        "  print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss: .4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOTsqFmeL6A1"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_seq, length, char_to_index, index_to_char):\n",
        "  model.eval()\n",
        "  seq = [char_to_index[c] for c in start_seq]\n",
        "  generated = start_seq\n",
        "  for _ in range(length):\n",
        "    x = torch.tensor([seq[-seq_length:]])\n",
        "    x_onehot = torch.nn.functional.one_hot(x, num_classes=len(chars)).float()\n",
        "    with torch.no_grad():\n",
        "      out = model(x_onehot)\n",
        "      pred = out.argmax(dim=1).item()\n",
        "    generated += index_to_char[pred]\n",
        "    seq.append(pred)\n",
        "  return generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-CmqiaDNGf6"
      },
      "outputs": [],
      "source": [
        "print(\"Generated Text: \")\n",
        "print(generate_text(model, \"Once\", 100, char_to_index, index_to_char))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcQR3irVNY9v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70970e51"
      },
      "source": [
        "## ðŸ“¦ Exporting Model and Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a04be79"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pickle\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), \"text_generator_model.pth\")\n",
        "\n",
        "# Save vocab and mappings\n",
        "with open(\"vocab.pkl\", \"wb\") as f:\n",
        "    pickle.dump(vocab, f)\n",
        "\n",
        "with open(\"char_to_idx.pkl\", \"wb\") as f:\n",
        "    pickle.dump(char_to_idx, f)\n",
        "\n",
        "with open(\"idx_to_char.pkl\", \"wb\") as f:\n",
        "    pickle.dump(idx_to_char, f)\n",
        "\n",
        "print(\"âœ… Model and mappings exported successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8896ebe2"
      },
      "source": [
        "## ðŸ§  Text Generation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22878943"
      },
      "outputs": [],
      "source": [
        "def generate_text(start_seq=\"The\", length=300):\n",
        "    model.eval()\n",
        "    input_seq = torch.tensor([char_to_idx[c] for c in start_seq], dtype=torch.long).unsqueeze(0)\n",
        "    hidden = None\n",
        "    result = start_seq\n",
        "\n",
        "    for _ in range(length):\n",
        "        with torch.no_grad():\n",
        "            output, hidden = model(input_seq, hidden)\n",
        "            probs = torch.nn.functional.softmax(output[-1], dim=0).cpu()\n",
        "            next_char_idx = torch.multinomial(probs, 1).item()\n",
        "            next_char = idx_to_char[next_char_idx]\n",
        "\n",
        "        result += next_char\n",
        "        input_seq = torch.tensor([[next_char_idx]], dtype=torch.long)\n",
        "\n",
        "    return result\n",
        "\n",
        "# Example usage\n",
        "print(generate_text(\"The future of AI\", 500))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2da4a017"
      },
      "source": [
        "## ðŸ§ª CLI Support (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bf6fc31"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    prompt = input(\"Enter a blog title or starting text: \")\n",
        "    print(\"\\nGenerated Blog:\\n\")\n",
        "    print(generate_text(prompt, 500))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
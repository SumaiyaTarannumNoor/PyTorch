{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAjwqVxgThnt",
        "outputId": "5ccbfcdd-d669-46f1-be99-13b25b4b83cc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct  3 18:20:57 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub gradio torch torchvision torchtext torchmetrics tqdm pandas numpy scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiVK3l2DgiNK",
        "outputId": "880bcb2d-e2e2-4a95-e1e6-b912a71ff56e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.47.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Collecting torchtext\n",
            "  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.9)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.19.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.37.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.1.10)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchtext, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2 torchtext-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "_DvDo_AGg1w4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"grouplens/movielens-20m-dataset\")\n",
        "print(f\"Path to dataset files: {path}\")\n",
        "\n",
        "RATINGS_CSV = os.path.join(path, \"rating.csv\")\n",
        "MOVIES_CSV = os.path.join(path, \"rating.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F0-AwmZj8Sy",
        "outputId": "0b8013db-b246-4c42-acd2-471a73c89699"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/grouplens/movielens-20m-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 195M/195M [00:05<00:00, 39.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/grouplens/movielens-20m-dataset/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = pd.read_csv(RATINGS_CSV)\n",
        "movies = pd.read_csv(MOVIES_CSV)\n",
        "\n",
        "print(\"Missing values in ratings:\\n\", ratings.isnull().sum())\n",
        "print(\"Missing values in movies:\\n\", movies.isnull().sum())\n",
        "\n",
        "for col in ratings.columns:\n",
        "  if ratings[col].isnull().sum() > 0:\n",
        "    if ratings[col].dtype in [np.float64, np.int64]:\n",
        "      ratings[col].fillna(ratings[col].mean(), inplace=True)\n",
        "    else:\n",
        "      ratings.drop(columns=[col], inplace=True)\n",
        "\n",
        "for col in movies.columns:\n",
        "  if movies[col].isnull().sum() > 0:\n",
        "    if movies[col].dtype == 'object':\n",
        "      movies.drop(column=[col], inplace=True)\n",
        "\n",
        "\n",
        "user2idx = {u:i for i, u in enumerate(ratings['userId'].unique())}\n",
        "movie2idx = {m:i for i, m in enumerate(ratings['movieId'].unique())}\n",
        "idx2movie = {i:m for m, i in movie2idx.items()}\n",
        "\n",
        "n_users = len(user2idx)\n",
        "n_movies = len(movie2idx)\n",
        "\n",
        "print(f\"Users: {n_users}, Movies: {n_movies}, Ratings: {len(ratings)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cbiwm5ynlp4i",
        "outputId": "2c24f806-b73d-455e-bb01-72b360d1d677"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in ratings:\n",
            " userId       0\n",
            "movieId      0\n",
            "rating       0\n",
            "timestamp    0\n",
            "dtype: int64\n",
            "Missing values in movies:\n",
            " userId       0\n",
            "movieId      0\n",
            "rating       0\n",
            "timestamp    0\n",
            "dtype: int64\n",
            "Users: 138493, Movies: 26744, Ratings: 20000263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_val , test = train_test_split(ratings, test_size=0.20, random_state=42)\n",
        "train, val = train_test_split(train_val, test_size=0.125, random_state=42)\n",
        "\n",
        "print(f\"Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmOCBACVq998",
        "outputId": "d2ddc8c3-cf7e-4ed8-e5c3-0ffb70cecb6f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 14000183, Val: 2000027, Test: 4000053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MovieLensDataset(Dataset):\n",
        "    def __init__(self, df, user2idx, movie2idx):\n",
        "        # Map raw IDs to contiguous indices\n",
        "        self.users = torch.tensor(df['userId'].map(user2idx).values, dtype=torch.long)\n",
        "        self.movies = torch.tensor(df['movieId'].map(movie2idx).values, dtype=torch.long)\n",
        "        self.ratings = torch.tensor(df['rating'].values, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ratings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.users[idx], self.movies[idx], self.ratings[idx]\n",
        "\n",
        "\n",
        "train_ds = MovieLensDataset(train, user2idx, movie2idx)\n",
        "val_ds   = MovieLensDataset(val, user2idx, movie2idx)\n",
        "test_ds  = MovieLensDataset(test, user2idx, movie2idx)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=1024, shuffle=True)\n",
        "val_dl   = DataLoader(val_ds, batch_size=1024)\n",
        "test_dl  = DataLoader(test_ds, batch_size=1024)\n"
      ],
      "metadata": {
        "id": "YcuLdN34r5hw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MatrixFactorization(nn.Module):\n",
        "  def __init__(self, n_users, n_items, n_factors=100):\n",
        "    super().__init__()\n",
        "    self.user_emb = nn.Embedding(n_users, n_factors)\n",
        "    self.item_emb = nn.Embedding(n_items, n_factors)\n",
        "    self.user_bias = nn.Embedding(n_users, 1)\n",
        "    self.item_bias = nn.Embedding(n_items, 1)\n",
        "\n",
        "  def forward(self, users, items):\n",
        "    u = self.user_emb(users)\n",
        "    v = self.item_emb(items)\n",
        "    dot = (u*v).sum(1, keepdim=True)\n",
        "    return dot + self.user_bias(users) + self.item_bias(items)"
      ],
      "metadata": {
        "id": "Z8c8nSI9Qlgv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MatrixFactorization(n_users, n_movies, n_factors=64).to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "def train_one_epoch():\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  for u, m, r in train_dl:\n",
        "    u, m, r = u.to(device), m.to(device), r.to(device)\n",
        "    pred = model(u, m).squeeze()\n",
        "    loss = loss_fn(pred, r)\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    total_loss += loss.item() * len(r)\n",
        "  return total_loss / len(train_dl.dataset)\n",
        "\n",
        "def evaluate(dl):\n",
        "  model.eval()\n",
        "  total_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for u, m, r in dl:\n",
        "      u, m, r = u.to(device), m.to(device), r.to(device)\n",
        "      pred = model(u, m).squeeze()\n",
        "      loss = loss_fn(pred, r)\n",
        "      total_loss += loss.item() * len(r)\n",
        "  return total_loss / len(dl.dataset)\n",
        "\n",
        "\n",
        "for epoch in range(6):\n",
        "  train_loss = train_one_epoch()\n",
        "  val_loss = evaluate(val_dl)\n",
        "  print(f\"Epoch {epoch+1}: Train Loss:{train_loss:.4f} Validation Loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JakOTI9mM8iV",
        "outputId": "47598cf1-6492-4395-a439-ecadcce5b8e1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss:31.0421 Validation Loss: 9.3297\n",
            "Epoch 2: Train Loss:4.5868 Validation Loss: 3.3463\n",
            "Epoch 3: Train Loss:1.7320 Validation Loss: 2.0332\n",
            "Epoch 4: Train Loss:1.0606 Validation Loss: 1.5986\n",
            "Epoch 5: Train Loss:0.8439 Validation Loss: 1.4015\n",
            "Epoch 6: Train Loss:0.7456 Validation Loss: 1.2898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_topN_fast(model, user_idx, seen_indices, N=10, batch_size=1024):\n",
        "    model.eval()\n",
        "    recs = []\n",
        "\n",
        "    all_items = torch.arange(n_movies).to(device)\n",
        "    scores_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, n_movies, batch_size):\n",
        "            items_batch = all_items[i:i+batch_size]\n",
        "            users_batch = torch.tensor([user_idx]*len(items_batch)).to(device)\n",
        "            scores_batch = model(users_batch, items_batch).squeeze()\n",
        "            scores_list.append(scores_batch)\n",
        "\n",
        "    scores = torch.cat(scores_list).cpu().numpy()\n",
        "    scores[list(seen_indices)] = -np.inf  # ignore seen items\n",
        "    top_idx = np.argsort(-scores)[:N]\n",
        "    return top_idx"
      ],
      "metadata": {
        "id": "t_84v6HWm40p"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "sample_users = random.sample(list(test_truth.keys()), min(2000, len(test_truth)))\n",
        "test_truth_sample = {u: test_truth[u] for u in sample_users}\n"
      ],
      "metadata": {
        "id": "PB1HwMEAm9HM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precompute movie indices for test users\n",
        "test_truth_idx = {}\n",
        "seen_indices = {}\n",
        "for user_id in sample_users:\n",
        "    test_truth_idx[user_id] = set(movie2idx[m] for m in test_truth[user_id] if m in movie2idx)\n",
        "    seen_indices[user_id] = set(movie2idx[m] for m in train[train['userId']==user_id]['movieId'] if m in movie2idx)\n"
      ],
      "metadata": {
        "id": "QPDiYZo8m_Ce"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def precision_recall_ndcg_fast(model, test_users, test_truth_idx, seen_indices, K=10):\n",
        "    precisions, recalls, ndcgs = [], [], []\n",
        "\n",
        "    for user_id in test_users:\n",
        "        recs = recommend_topN_fast(model, user2idx[user_id], seen_indices[user_id], N=K)\n",
        "        relevant = test_truth_idx[user_id]\n",
        "\n",
        "        # metrics\n",
        "        prec = len([r for r in recs if r in relevant]) / K\n",
        "        rec = len([r for r in recs if r in relevant]) / len(relevant)\n",
        "        dcg = sum([1 / math.log2(i + 2) for i, r in enumerate(recs) if r in relevant])\n",
        "        idcg = sum([1 / math.log2(i + 2) for i in range(min(len(relevant), K))])\n",
        "        ndcg = dcg / idcg if idcg>0 else 0\n",
        "\n",
        "        precisions.append(prec)\n",
        "        recalls.append(rec)\n",
        "        ndcgs.append(ndcg)\n",
        "\n",
        "    return np.mean(precisions), np.mean(recalls), np.mean(ndcgs)\n",
        "\n",
        "# Evaluate\n",
        "p10, r10, n10 = precision_recall_ndcg_fast(model, sample_users, test_truth_idx, seen_indices)\n",
        "print(f\"Precision@10: {p10:.4f}, Recall@10: {r10:.4f}, NDCG@10: {n10:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqoAgIQEnC-8",
        "outputId": "dd3ceeb5-43ef-4eb4-c2e1-aaa66031dccb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision@10: 0.0000, Recall@10: 0.0000, NDCG@10: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_movies(user_id, N=10):\n",
        "  if user_id not in user2idx:\n",
        "    print(f\"User ID {user_id} not found.\")\n",
        "    return []\n",
        "\n",
        "  uidx = user2idx[user_id]\n",
        "\n",
        "  user_train_ratings = train[train['userId'] == user_id]\n",
        "  seen_movie_ids = set(user_train_ratings['movieId'].values)\n",
        "\n",
        "  seen_movie_indices = set(movie2idx[movie_id] for movie_id in seen_movie_ids if movie_id in movie2idx)\n",
        "\n",
        "  rec_idx = recommend_topN_fast(model, uidx, seen_movie_indices, N=N)\n",
        "  rec_titles = []\n",
        "  for idx in rec_idx:\n",
        "    movie_id = idx2movie[idx]\n",
        "    title_row = movies[movies['movieId']==movie_id]\n",
        "    if not title_row.empty:\n",
        "      rec_titles.append(f\"Movie ID: {movie_id}\")\n",
        "    else:\n",
        "      rec_titles.append(f\"Movie ID: {movie_id} (Title not found)\")\n",
        "  return rec_titles\n",
        "\n",
        "user_to_recommend = 1\n",
        "recommendations = recommend_movies(user_to_recommend, N=10)\n",
        "print(f\"Top 10 recommendations for user {user_to_recommend}:\")\n",
        "for rec in recommendations:\n",
        "  print(rec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6f3FImWg_sY",
        "outputId": "966e6017-c585-41ed-d5ff-40b376b73ece"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 recommendations for user 1:\n",
            "Movie ID: 94904\n",
            "Movie ID: 47482\n",
            "Movie ID: 83138\n",
            "Movie ID: 131262\n",
            "Movie ID: 101920\n",
            "Movie ID: 114340\n",
            "Movie ID: 130060\n",
            "Movie ID: 91921\n",
            "Movie ID: 83823\n",
            "Movie ID: 117488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, pickle\n",
        "\n",
        "torch.save(model.state_dict(), \"mf_model.pt\")\n",
        "with open(\"mappings.pkl\", \"wb\") as f:\n",
        "  pickle.dump({\"user2idx\": user2idx, \"movie2idx\": movie2idx, \"idx2movie\": idx2movie}, f)\n",
        "movies.to_csv(\"movies_metadata.csv\", index=False)"
      ],
      "metadata": {
        "id": "ry3IzR-ZiL8u"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "J60cy0y2Wqtm",
        "outputId": "9e7246aa-9b69-41f5-f51c-77c43667535c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Oct  4 09:46:40 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   77C    P0             31W /   70W |     334MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ody1M__Esk1W",
        "outputId": "36fe36e9-27c3-4321-94e4-7fe2ee5bbec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.47.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.9)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.19.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.37.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.1.10)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install kagglehub gradio torch torchvision torchtext torchmetrics tqdm pandas numpy scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import kagglehub"
      ],
      "metadata": {
        "id": "uve82j9etFIo"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"grouplens/movielens-20m-dataset\")\n",
        "print(f\"Dataset downloaded to: {path}\")\n",
        "\n",
        "# -------------------------------\n",
        "# STEP 1: Find actual CSV files in the downloaded path\n",
        "# -------------------------------\n",
        "# This avoids filename/path mismatches\n",
        "ratings_files = [f for f in os.listdir(path) if \"rating\" in f.lower() and f.endswith(\".csv\")]\n",
        "movies_files = [f for f in os.listdir(path) if \"movie\" in f.lower() and f.endswith(\".csv\")]\n",
        "\n",
        "if not ratings_files or not movies_files:\n",
        "    raise FileNotFoundError(\"Ratings or movies CSV not found in the dataset folder.\")\n",
        "\n",
        "RATINGS_CSV = os.path.join(path, ratings_files[0])\n",
        "MOVIES_CSV = os.path.join(path, movies_files[0])\n",
        "\n",
        "print(f\"Using ratings file: {RATINGS_CSV}\")\n",
        "print(f\"Using movies file: {MOVIES_CSV}\")\n",
        "\n",
        "ratings_full = pd.read_csv(RATINGS_CSV)\n",
        "movies_full = pd.read_csv(MOVIES_CSV)\n",
        "\n",
        "print(f\"Full ratings shape: {ratings_full.shape}\")\n",
        "print(f\"Full movies shape: {movies_full.shape}\")\n",
        "\n",
        "fraction = 0.2\n",
        "ratings = ratings_full.sample(frac=fraction, random_state=42)\n",
        "\n",
        "movies= movies_full[movies_full['movieId'].isin(ratings['movieId'].unique())].copy()\n",
        "\n",
        "print(f\"Fraction ratings shape: {ratings.shape}\")\n",
        "print(f\"Fraction movies shape: {movies.shape}\")\n",
        "\n",
        "print(f\"Missing values in fraction ratings:\\n{ratings.isnull().sum()}\")\n",
        "print(f\"Missing values in fraction movies:\\n{movies.isnull().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az4MOlp2txO3",
        "outputId": "b184c9b4-b3e5-4346-f913-320f5283e3ed"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'movielens-20m-dataset' dataset.\n",
            "Dataset downloaded to: /kaggle/input/movielens-20m-dataset\n",
            "Using ratings file: /kaggle/input/movielens-20m-dataset/rating.csv\n",
            "Using movies file: /kaggle/input/movielens-20m-dataset/movie.csv\n",
            "Full ratings shape: (20000263, 4)\n",
            "Full movies shape: (27278, 3)\n",
            "Fraction ratings shape: (4000053, 4)\n",
            "Fraction movies shape: (20357, 3)\n",
            "Missing values in fraction ratings:\n",
            "userId       0\n",
            "movieId      0\n",
            "rating       0\n",
            "timestamp    0\n",
            "dtype: int64\n",
            "Missing values in fraction movies:\n",
            "movieId    0\n",
            "title      0\n",
            "genres     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_ids = ratings['userId'].unique()\n",
        "movie_ids = ratings['movieId'].unique()\n",
        "\n",
        "user2idx = {u:i for i,u in enumerate(user_ids)}\n",
        "movie2idx = {m:i for i,m in enumerate(movie_ids)}\n",
        "idx2movie = {i:m for m, i in movie2idx.items()}\n",
        "\n",
        "movieid2title = movies.set_index(\"movieId\")['title'].to_dict()\n",
        "\n",
        "n_users = len(user2idx)\n",
        "n_movies = len(movie2idx)\n",
        "\n",
        "print(f\"Users:{n_users}, Movies: {n_movies}, Ratings: {len(ratings)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ8Dm7p9w8Do",
        "outputId": "f54a6c76-ad38-4bb7-eb36-b39dab535d2a"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Users:138339, Movies: 20357, Ratings: 4000053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train, Test, Validation Split -- 70% /20% / 10%\n",
        "\n",
        "train_val, test = train_test_split(ratings, test_size=0.20, random_state=42)\n",
        "train, val = train_test_split(train_val, test_size=0.125, random_state=42)\n",
        "\n",
        "print(f\"Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8PZ471a0bi_",
        "outputId": "10ae4f40-fa7e-4353-9d37-094d10a5f490"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 2800036, Val: 400006, Test: 800011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MovieLensDataset(Dataset):\n",
        "  def __init__(self, df, user2idx, movie2idx):\n",
        "    self.users = torch.tensor(df['userId'].map(user2idx).values, dtype=torch.long)\n",
        "    self.movies = torch.tensor(df['movieId'].map(movie2idx).values, dtype=torch.long)\n",
        "    self.ratings = torch.tensor(df['rating'].values, dtype=torch.float32)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.ratings)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.users[idx], self.movies[idx], self.ratings[idx]\n",
        "\n",
        "\n",
        "\n",
        "train_ds = MovieLensDataset(train, user2idx, movie2idx)\n",
        "val_ds = MovieLensDataset(val, user2idx, movie2idx)\n",
        "test_ds = MovieLensDataset(test, user2idx, movie2idx)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=1024, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=1024)\n",
        "test_dl = DataLoader(test_ds, batch_size=1024)"
      ],
      "metadata": {
        "id": "5sJlpkTo1FMr"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MatrixFactorization(nn.Module):\n",
        "  def __init__(self, n_users, n_items, n_factors=100):\n",
        "    super().__init__()\n",
        "    self.user_emb = nn.Embedding(n_users, n_factors)\n",
        "    self.item_emb = nn.Embedding(n_items, n_factors)\n",
        "    self.user_bias = nn.Embedding(n_users, 1)\n",
        "    self.item_bias = nn.Embedding(n_items, 1)\n",
        "\n",
        "    nn.init.normal_(self.user_emb.weight, std=0.01)\n",
        "    nn.init.normal_(self.item_emb.weight, std=0.01)\n",
        "    nn.init.zeros_(self.user_bias.weight)\n",
        "    nn.init.zeros_(self.item_bias.weight)\n",
        "\n",
        "  def forward(self, users, items):\n",
        "    u = self.user_emb(users)\n",
        "    v = self.item_emb(items)\n",
        "    dot = (u * v).sum(1)\n",
        "    return dot + self.user_bias(users).squeeze() + self.item_bias(items).squeeze()\n"
      ],
      "metadata": {
        "id": "Y07MPDgR4Utb"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MatrixFactorization(n_users, n_movies, n_factors=64).to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-5)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "def train_one_epoch():\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "  for u, m, r in train_dl:\n",
        "    u, m, r = u.to(device), m.to(device), r.to(device)\n",
        "    pred = model(u, m)\n",
        "    loss = loss_fn(pred, r)\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    total_loss += loss.item() * r.size(0)\n",
        "  return total_loss / len(train_dl.dataset)\n",
        "\n",
        "def evaluate(dataloader):\n",
        "  model.eval()\n",
        "  total_loss = 0.0\n",
        "  with torch.no_grad():\n",
        "    for u, m, r in dataloader:\n",
        "      u, m, r = u.to(device), m.to(device), r.to(device)\n",
        "      pred = model(u, m)\n",
        "      loss = loss_fn(pred, r)\n",
        "      total_loss += loss.item() * r.size(0)\n",
        "  return total_loss / len(dataloader.dataset)\n",
        "\n",
        "\n",
        "for epoch in range(46):\n",
        "  train_loss = train_one_epoch()\n",
        "  val_loss = evaluate(val_dl)\n",
        "  print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f} ; Validation Loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQfoapfG6f-I",
        "outputId": "856157b9-1e68-4b8c-c76b-aac62df56d6d"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 4.3711 ; Validation Loss: 1.3711\n",
            "Epoch 2: Train Loss: 1.1527 ; Validation Loss: 1.1063\n",
            "Epoch 3: Train Loss: 1.0325 ; Validation Loss: 1.0500\n",
            "Epoch 4: Train Loss: 0.9864 ; Validation Loss: 1.0162\n",
            "Epoch 5: Train Loss: 0.9442 ; Validation Loss: 0.9895\n",
            "Epoch 6: Train Loss: 0.9020 ; Validation Loss: 0.9658\n",
            "Epoch 7: Train Loss: 0.8596 ; Validation Loss: 0.9442\n",
            "Epoch 8: Train Loss: 0.8149 ; Validation Loss: 0.9283\n",
            "Epoch 9: Train Loss: 0.7679 ; Validation Loss: 0.9115\n",
            "Epoch 10: Train Loss: 0.7208 ; Validation Loss: 0.9003\n",
            "Epoch 11: Train Loss: 0.6784 ; Validation Loss: 0.8913\n",
            "Epoch 12: Train Loss: 0.6417 ; Validation Loss: 0.8854\n",
            "Epoch 13: Train Loss: 0.6105 ; Validation Loss: 0.8809\n",
            "Epoch 14: Train Loss: 0.5849 ; Validation Loss: 0.8787\n",
            "Epoch 15: Train Loss: 0.5643 ; Validation Loss: 0.8759\n",
            "Epoch 16: Train Loss: 0.5476 ; Validation Loss: 0.8742\n",
            "Epoch 17: Train Loss: 0.5341 ; Validation Loss: 0.8724\n",
            "Epoch 18: Train Loss: 0.5231 ; Validation Loss: 0.8717\n",
            "Epoch 19: Train Loss: 0.5141 ; Validation Loss: 0.8715\n",
            "Epoch 20: Train Loss: 0.5076 ; Validation Loss: 0.8711\n",
            "Epoch 21: Train Loss: 0.5021 ; Validation Loss: 0.8706\n",
            "Epoch 22: Train Loss: 0.4971 ; Validation Loss: 0.8703\n",
            "Epoch 23: Train Loss: 0.4932 ; Validation Loss: 0.8702\n",
            "Epoch 24: Train Loss: 0.4903 ; Validation Loss: 0.8700\n",
            "Epoch 25: Train Loss: 0.4875 ; Validation Loss: 0.8702\n",
            "Epoch 26: Train Loss: 0.4853 ; Validation Loss: 0.8705\n",
            "Epoch 27: Train Loss: 0.4835 ; Validation Loss: 0.8704\n",
            "Epoch 28: Train Loss: 0.4821 ; Validation Loss: 0.8706\n",
            "Epoch 29: Train Loss: 0.4807 ; Validation Loss: 0.8708\n",
            "Epoch 30: Train Loss: 0.4796 ; Validation Loss: 0.8710\n",
            "Epoch 31: Train Loss: 0.4782 ; Validation Loss: 0.8711\n",
            "Epoch 32: Train Loss: 0.4773 ; Validation Loss: 0.8713\n",
            "Epoch 33: Train Loss: 0.4764 ; Validation Loss: 0.8710\n",
            "Epoch 34: Train Loss: 0.4759 ; Validation Loss: 0.8712\n",
            "Epoch 35: Train Loss: 0.4752 ; Validation Loss: 0.8714\n",
            "Epoch 36: Train Loss: 0.4745 ; Validation Loss: 0.8715\n",
            "Epoch 37: Train Loss: 0.4741 ; Validation Loss: 0.8719\n",
            "Epoch 38: Train Loss: 0.4735 ; Validation Loss: 0.8718\n",
            "Epoch 39: Train Loss: 0.4729 ; Validation Loss: 0.8722\n",
            "Epoch 40: Train Loss: 0.4724 ; Validation Loss: 0.8720\n",
            "Epoch 41: Train Loss: 0.4722 ; Validation Loss: 0.8723\n",
            "Epoch 42: Train Loss: 0.4718 ; Validation Loss: 0.8720\n",
            "Epoch 43: Train Loss: 0.4713 ; Validation Loss: 0.8723\n",
            "Epoch 44: Train Loss: 0.4710 ; Validation Loss: 0.8728\n",
            "Epoch 45: Train Loss: 0.4709 ; Validation Loss: 0.8727\n",
            "Epoch 46: Train Loss: 0.4703 ; Validation Loss: 0.8726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "test_truth = defaultdict(list)\n",
        "for row in test.itertuples(index=False):\n",
        "  uid = row.userId\n",
        "  mid = row.movieId\n",
        "  if row.rating >= 4.0:\n",
        "    if uid in user2idx and mid in movie2idx:\n",
        "      test_truth[uid].append(mid)\n",
        "\n",
        "test_truth_idx = {}\n",
        "for uid, mids in test_truth.items():\n",
        "  test_truth_idx[uid] = set(movie2idx[m] for m in mids if m in movie2idx)\n",
        "\n",
        "seen_indicies = {}\n",
        "train_grouped = train.groupby('userId')['movieId'].apply(list).to_dict()\n",
        "for uid in train_grouped:\n",
        "  seen_indicies[uid] = set(movie2idx[m] for m in train_grouped[uid] if m in movie2idx)\n",
        "\n",
        "print(f\"Prepared test_truth and seen_indicies for evaluation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq2rX2OD80jO",
        "outputId": "e96935f9-82ce-477c-ed7b-5a8731ad98bc"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepared test_truth and seen_indicies for evaluation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_topN_fast(model, user_idx, seen_indicies_set, N=10, batch_size=2048):\n",
        "  model.eval()\n",
        "  all_items = torch.arange(n_movies, device=device)\n",
        "  scores_chunks = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for start in range(0, n_movies, batch_size):\n",
        "      end = min(start + batch_size, n_movies)\n",
        "      items_batch = all_items[start:end]\n",
        "      users_batch = torch.full((end - start,), user_idx, dtype = torch.long, device = device)\n",
        "      scores_batch = model(users_batch, items_batch)\n",
        "      scores_chunks.append(scores_batch.cpu())\n",
        "\n",
        "\n",
        "  scores = torch.cat(scores_chunks).numpy()\n",
        "\n",
        "  if seen_indicies_set:\n",
        "    mask = np.array(list(seen_indicies_set))\n",
        "    scores[list(seen_indicies_set)] = -np.inf\n",
        "\n",
        "\n",
        "  top_idx = np.argpartition(-scores, N)[:N]\n",
        "  top_idx = top_idx[np.argsort(-scores[top_idx])]\n",
        "  return top_idx.tolist()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0x9Zh26u_ROj"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation: Precision@K, Recall@K, NDCG@K"
      ],
      "metadata": {
        "id": "W4aa4xx_BpQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "\n",
        "def precision_recall_ndcg_fast(model, user_ids, test_truth_idx, seen_indicies, K=10):\n",
        "  precisions, recalls, ndcgs = [], [], []\n",
        "  for uid in user_ids:\n",
        "    if uid not in user2idx:\n",
        "      continue\n",
        "    relevent = test_truth_idx.get(uid, set())\n",
        "    if len(relevent) == 0:\n",
        "      continue\n",
        "\n",
        "    recs = recommend_topN_fast(model, user2idx[uid], seen_indicies.get(uid, set()), N=K)\n",
        "    hit_count = sum(1 for r in recs if r in relevent)\n",
        "    prec = hit_count / K\n",
        "    rec = hit_count / len(relevent)\n",
        "    dcg = sum(1 / math.log2(i+2) for i, r in enumerate(recs) if r in relevent)\n",
        "    idcg = sum(1 / math.log2(i+2) for i in range(min(len(relevent), K)))\n",
        "    ndcg = dcg / idcg if idcg > 0 else 0\n",
        "    precisions.append(prec); recalls.append(rec); ndcgs.append(ndcg)\n",
        "  return np.mean(precisions), np.mean(recalls), np.mean(ndcgs)"
      ],
      "metadata": {
        "id": "WBdmsVIt-fNu"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_test_users = list(test_truth_idx.keys())\n",
        "sample_users = random.sample(all_test_users, min(2000, len(all_test_users)))\n",
        "p10, r10, n10 = precision_recall_ndcg_fast(model, sample_users, test_truth_idx, seen_indicies, K=10)\n",
        "print(f\"Precision@10: {p10:.4f}, Recall@10: {r10:.4f}, NDCG@10: {n10:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpF7zeCcEF15",
        "outputId": "98296287-66bd-4fef-f121-a7ade04429de"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision@10: 0.0156, Recall@10: 0.0517, NDCG@10: 0.0346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_movies(user_id, N=10):\n",
        "  if user_id not in user2idx:\n",
        "    print(f\"User ID {user_id} not found.0\")\n",
        "    return []\n",
        "\n",
        "  uidx = user2idx[user_id]\n",
        "  seen_set = seen_indicies.get(user_id, set())\n",
        "\n",
        "  top_movies_indicies = recommend_topN_fast(model, uidx, seen_set, N=N)\n",
        "\n",
        "  titles = []\n",
        "\n",
        "  for midx in top_movies_indicies:\n",
        "    raw_movie_id = idx2movie.get(midx, None)\n",
        "    title = movieid2title.get(raw_movie_id, None)\n",
        "    if title:\n",
        "      titles.append(title)\n",
        "    else:\n",
        "      titles.append(f\"Movie ID {raw_movie_id}\")\n",
        "  return titles\n",
        "\n",
        "\n",
        "try:\n",
        "    user_to_recommend = int(input('Enter user ID to get movie recommendation: '))\n",
        "    recs = recommend_movies(user_to_recommend, N=10)\n",
        "\n",
        "    if len(recs) == 0:\n",
        "      print(\"No recommendations found.\")\n",
        "    else:\n",
        "      print(f\"\\nTop{len(recs)} recommendations for user {user_to_recommend}: \\n\")\n",
        "      for i, t in enumerate(recs, 1):\n",
        "        print(f\"{i}. {t}\")\n",
        "except ValueError:\n",
        "       print(\"Invalid Input. Please enter a numeric user ID...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1C0XJ-oFGVx",
        "outputId": "02317ab1-5782-411f-f2aa-48cad9d46448"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter user ID to get movie recommendation: 122\n",
            "\n",
            "Top10 recommendations for user 122: \n",
            "\n",
            "1. Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)\n",
            "2. One Flew Over the Cuckoo's Nest (1975)\n",
            "3. Fargo (1996)\n",
            "4. Pulp Fiction (1994)\n",
            "5. Schindler's List (1993)\n",
            "6. Godfather, The (1972)\n",
            "7. American Beauty (1999)\n",
            "8. Casablanca (1942)\n",
            "9. To Kill a Mockingbird (1962)\n",
            "10. Blade Runner (1982)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Deployment"
      ],
      "metadata": {
        "id": "eJJPz8SyMyn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "torch.save(model.state_dict(), \"mf_model.pt\")\n",
        "with open(\"mapping.pkl\", \"wb\") as f:\n",
        "  pickle.dump({\"user2idx\": user2idx, \"movie2idx\": movie2idx, \"idx2movie\": idx2movie, \"movieid2title\": movieid2title}, f)\n",
        "movies.to_csv(\"movies_metadata.csv\", index=False)\n",
        "print(\"Saved: mf_model.pf, mappings.pkl, movies_metadata.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWOlDiPtMr7c",
        "outputId": "f9ddfc6c-585a-4c51-ac66-c987f8c55077"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: mf_model.pf, mappings.pkl, movies_metadata.csv\n"
          ]
        }
      ]
    }
  ]
}